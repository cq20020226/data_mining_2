import json
import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter
import os
import matplotlib
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import apriori, association_rules
import matplotlib.pyplot as plt
from collections import defaultdict

plt.rcParams['font.sans-serif'] = ['WenQuanYi Zen Hei']
plt.rcParams['axes.unicode_minus'] = False


# è·¯å¾„è®¾ç½®
DATA_PATH = "/data/data_mining_2/output/data_preprocess_output/purchase_history_final.jsonl"  # æ›¿æ¢ä¸ºä½ çš„æ–‡ä»¶å
OUTPUT_DIR = "/data/DM_work/output/analysis_output"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# åŠ è½½æ•°æ®
# def load_data(path):
#     with open(path, 'r', encoding='utf-8') as f:
#         return json.load(f)
# def load_data(path):
#     return load_jsonl_as_list(path)
# def load_jsonl_as_list(path):
#     """å°† .jsonl æ–‡ä»¶è½¬æ¢ä¸º JSON åˆ—è¡¨æ ¼å¼"""
#     data = []
#     with open(path, 'r', encoding='utf-8') as f:
#         for line in f:
#             line = line.strip()
#             if line:
#                 try:
#                     data.append(json.loads(line))
#                 except json.JSONDecodeError:
#                     print(f"âš ï¸ è·³è¿‡æ— æ³•è§£æçš„è¡Œ: {line}")
#     return data
def load_jsonl_as_list(path, limit=None):
    """å°† .jsonl æ–‡ä»¶è½¬æ¢ä¸º JSON åˆ—è¡¨æ ¼å¼ï¼ˆå¯é™åˆ¶æœ€å¤šè¯»å–å¤šå°‘è¡Œï¼‰"""
    data = []
    with open(path, 'r', encoding='utf-8') as f:
        for i, line in enumerate(f):
            if limit is not None and i >= limit:
                break
            line = line.strip()
            if line:
                try:
                    data.append(json.loads(line))
                except json.JSONDecodeError:
                    print(f"âš ï¸ è·³è¿‡æ— æ³•è§£æçš„è¡Œ: {line}")
    return data

# æå–æ¯ä¸ªè®¢å•ä¸­çš„ major_category é›†åˆ
def extract_major_categories(orders):
    return [list(set(item['major_category'] for item in order['items'])) for order in orders]


def task1(data):
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    task_output_dir = os.path.join(OUTPUT_DIR, "task1")
    os.makedirs(task_output_dir, exist_ok=True)


    # æå–è®¢å•ä¸­æ‰€æœ‰å•†å“çš„å¤§ç±»
    transactions = extract_major_categories(data)

    # One-hot ç¼–ç 
    te = TransactionEncoder()
    te_ary = te.fit(transactions).transform(transactions)
    df = pd.DataFrame(te_ary, columns=te.columns_)

    # 1. æŒ–æ˜é¢‘ç¹é¡¹é›†ï¼ˆæ”¯æŒåº¦ â‰¥ 0.02ï¼‰
    frequent_itemsets = apriori(df, min_support=0.02, use_colnames=True)
    frequent_itemsets.to_csv(f"{task_output_dir}/task1_frequent_itemsets.csv", index=False)

    # 2. ç”Ÿæˆå…³è”è§„åˆ™ï¼ˆç½®ä¿¡åº¦ â‰¥ 0.5ï¼‰
    rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.5)
    rules.to_csv(f"{task_output_dir}/task1_rules.csv", index=False)

    # 3. ç‰¹åˆ«ç­›é€‰å‡ºä¸â€œç”µå­äº§å“â€ç›¸å…³çš„è§„åˆ™
    electronics_rules = rules[
        rules['antecedents'].apply(lambda x: 'ç”µå­äº§å“' in x) |
        rules['consequents'].apply(lambda x: 'ç”µå­äº§å“' in x)
    ]
    electronics_rules.to_csv(f"{task_output_dir}/task1_electronics_rules.csv", index=False)

    print("âœ… ä»»åŠ¡1å®Œæˆï¼šé¢‘ç¹é¡¹é›†ã€å…³è”è§„åˆ™ã€ç”µå­äº§å“ç›¸å…³è§„åˆ™å·²ä¿å­˜")
    return frequent_itemsets, rules, electronics_rules

def task2(data):
    # if not os.path.exists(OUTPUT_DIR):
    #     os.makedirs(OUTPUT_DIR)
    task_output_dir = os.path.join(OUTPUT_DIR, "task2")
    os.makedirs(task_output_dir, exist_ok=True)

    high_value_data = []
    payment_counter = Counter()

    # 1ï¸âƒ£ ç­›é€‰å«æœ‰å•ä»· â‰¥ 5000 çš„å•†å“çš„è®¢å•
    for order in data:
        if any(item['price'] >= 5000 for item in order['items']):
            payment_method = order['payment_method']
            payment_counter[payment_method] += 1

            categories = list(set(item['major_category'] for item in order['items']))
            transaction = categories + [payment_method]
            high_value_data.append(transaction)

    # 2ï¸âƒ£ ä¿å­˜é¦–é€‰æ”¯ä»˜æ–¹å¼ç»Ÿè®¡
    payment_df = pd.DataFrame(payment_counter.items(), columns=["payment_method", "count"])
    payment_df = payment_df.sort_values(by="count", ascending=False)
    payment_df.to_csv(f"{task_output_dir}/task2_payment_method_stats.csv", index=False)

    print("ğŸ’³ é«˜ä»·å•†å“è®¢å•ä¸­æ”¯ä»˜æ–¹å¼ç»Ÿè®¡å·²ä¿å­˜ï¼štask2_payment_method_stats.csv")

    # 3ï¸âƒ£ è½¬æ¢äº¤æ˜“æ ¼å¼
    te = TransactionEncoder()
    te_ary = te.fit(high_value_data).transform(high_value_data)
    df = pd.DataFrame(te_ary, columns=te.columns_)

    # 4ï¸âƒ£ æŒ–æ˜é¢‘ç¹é¡¹é›†å¹¶ä¿å­˜
    frequent_itemsets = apriori(df, min_support=0.01, use_colnames=True)
    frequent_itemsets.to_csv(f"{task_output_dir}/task2_frequent_itemsets.csv", index=False)
    print("ğŸ“¦ é¢‘ç¹é¡¹é›†å·²ä¿å­˜ï¼štask2_frequent_itemsets.csv")

    # 5ï¸âƒ£ ç”Ÿæˆå…³è”è§„åˆ™å¹¶ä¿å­˜
    rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.6)
    rules.to_csv(f"{task_output_dir}/task2_rules.csv", index=False)
    print("âœ… å…³è”è§„åˆ™å·²ä¿å­˜ï¼štask2_rules.csv")

    return rules


def task3(data):
    task_output_dir = os.path.join(OUTPUT_DIR, "task3")
    os.makedirs(task_output_dir, exist_ok=True)


    # === æ„å»ºåŸºç¡€ DataFrame ===
    df = pd.DataFrame(data)
    df['purchase_date'] = pd.to_datetime(df['purchase_date'])
    df['month'] = df['purchase_date'].dt.month
    df['quarter'] = df['purchase_date'].dt.quarter
    df['weekday'] = df['purchase_date'].dt.dayofweek  # 0=Monday, 6=Sunday

    # âœ… ä»»åŠ¡3.1ï¼šå­£èŠ‚æ€§åˆ†æï¼ˆå­£åº¦ & å‘¨å‡ ï¼‰
    # â€”â€” å­£åº¦åˆ†æ
    quarter_counts = defaultdict(Counter)
    for _, row in df.iterrows():
        quarter = row['quarter']
        for item in row['items']:
            quarter_counts[quarter][item['major_category']] += 1
    pd.DataFrame(quarter_counts).fillna(0).astype(int).to_csv(f"{task_output_dir}/task3_quarterly_category_counts.csv")
    print("å®Œæˆ3.1")
    # â€”â€” æ¯å‘¨å‘¨æœŸåˆ†æ
    weekday_counts = defaultdict(Counter)
    for _, row in df.iterrows():
        weekday = row['weekday']
        for item in row['items']:
            weekday_counts[weekday][item['major_category']] += 1
    pd.DataFrame(weekday_counts).fillna(0).astype(int).to_csv(f"{task_output_dir}/task3_weekday_category_counts.csv")
    print("å®Œæˆ3.2")
    # âœ… ä»»åŠ¡3.2ï¼šå•†å“ç±»åˆ«æœˆåº¦è¶‹åŠ¿å›¾ï¼ˆå·²å®Œæˆï¼‰
    monthly_counts = []
    for month in range(1, 13):
        items = []
        for order in df[df['month'] == month]['items']:
            items.extend(item['major_category'] for item in order)
        count = Counter(items)
        monthly_counts.append(count)

    months = list(range(1, 13))
    plt.figure(figsize=(12, 6))
    for category in set(cat for counter in monthly_counts for cat in counter):
        plt.plot(months, [month_count.get(category, 0) for month_count in monthly_counts], label=category)

    plt.xlabel("æœˆä»½")
    plt.ylabel("è´­ä¹°æ•°é‡")
    plt.title("å•†å“å¤§ç±»çš„æœˆåº¦è´­ä¹°è¶‹åŠ¿")
    plt.legend(loc='upper right', fontsize='small')
    plt.tight_layout()
    plt.savefig(f"{task_output_dir}/task3_monthly_trends.png")
    plt.close()
    print("å®Œæˆ3.3")
    # âœ… ä»»åŠ¡3.3ï¼šæ—¶åºæ¨¡å¼åˆ†æï¼ˆå…ˆ A å B çš„å¤§ç±»å¯¹ï¼‰
    # é€»è¾‘ï¼šæŒ‰ç”¨æˆ·çš„è´­ä¹°æ—¶é—´å…ˆåæ’åºï¼Œæ”¶é›†æ¯ä¸ªç”¨æˆ·è´­ä¹°å¤§ç±»çš„é¡ºåº
    # å‡è®¾æ¯æ¡è®°å½•æ¥è‡ªä¸€ä¸ªç”¨æˆ·ï¼ˆå¦‚æœæœ‰ user_idï¼Œå¯ä»¥è¿›ä¸€æ­¥ç»†åŒ–ï¼‰
    # æ³¨æ„ï¼šè¿™é‡Œåªèƒ½åšç®€å•é¡ºåºï¼Œéä¸¥æ ¼é—´éš”å…³ç³»ï¼ˆå¦‚ä¹°äº†Aï¼Œæœªæ¥æŸæ—¶ä¹°Bï¼‰

    sequence_pairs = Counter()
    user_sequences = []

    df_sorted = df.sort_values('purchase_date')
    for _, row in df_sorted.iterrows():
        # è·å–è¯¥è®¢å•çš„å¤§ç±»é›†åˆï¼ˆå»é‡ï¼‰
        categories = list(set(item['major_category'] for item in row['items']))
        user_sequences.append(categories)

    # å»ºç«‹å¤§ç±»å¯¹çš„è½¬ç§»ï¼ˆå…ˆAåBï¼‰
    for i in range(len(user_sequences) - 1):
        current = user_sequences[i]
        next_ = user_sequences[i + 1]
        for a in current:
            for b in next_:
                if a != b:
                    sequence_pairs[(a, b)] += 1

    seq_df = pd.DataFrame([
        {"from_category": a, "to_category": b, "count": c}
        for (a, b), c in sequence_pairs.items()
    ])
    seq_df.sort_values(by="count", ascending=False).to_csv(f"{task_output_dir}/task3_sequential_category_pairs.csv", index=False)
    print("å®Œæˆ3.4")
    print("âœ… ä»»åŠ¡3å®Œæˆï¼š")
    print("  ğŸ“Š æœˆåº¦è¶‹åŠ¿å›¾å·²ä¿å­˜ä¸º task3_monthly_trends.png")
    print("  ğŸ“ å­£åº¦åˆ†ç±»ç»Ÿè®¡å·²ä¿å­˜ä¸º task3_quarterly_category_counts.csv")
    print("  ğŸ“ æ¯å‘¨åˆ†ç±»ç»Ÿè®¡å·²ä¿å­˜ä¸º task3_weekday_category_counts.csv")
    print("  ğŸ” æ—¶åºæ¨¡å¼å·²ä¿å­˜ä¸º task3_sequential_category_pairs.csv")


def task4(data):
    task_output_dir = os.path.join(OUTPUT_DIR, "task4")
    os.makedirs(task_output_dir, exist_ok=True)


    refund_data = []

    # 1ï¸âƒ£ æå–é€€æ¬¾è®¢å•ä¸­çš„å•†å“å¤§ç±»
    for order in data:
        if order['payment_status'] in ['å·²é€€æ¬¾', 'éƒ¨åˆ†é€€æ¬¾']:
            categories = list(set(item['major_category'] for item in order['items']))
            refund_data.append(categories)

    if refund_data:
        # 2ï¸âƒ£ è½¬æ¢æˆå¸ƒå°”å‹ç¼–ç 
        te = TransactionEncoder()
        te_ary = te.fit(refund_data).transform(refund_data)
        df = pd.DataFrame(te_ary, columns=te.columns_)

        # 3ï¸âƒ£ é¢‘ç¹é¡¹é›†æŒ–æ˜
        frequent_itemsets = apriori(df, min_support=0.005, use_colnames=True)
        frequent_itemsets.to_csv(f"{task_output_dir}/task4_frequent_itemsets.csv", index=False)
        print("ğŸ“¦ task4_frequent_itemsets.csv å·²ä¿å­˜")

        # 4ï¸âƒ£ å…³è”è§„åˆ™æŒ–æ˜
        rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.4)
        rules.to_csv(f"{task_output_dir}/task4_rules.csv", index=False)
        print("âœ… task4_rules.csv å·²ä¿å­˜ï¼šåŒ…å«é€€æ¬¾ç›¸å…³å•†å“ç»„åˆæ¨¡å¼")

        return rules
    else:
        # æ²¡æœ‰é€€æ¬¾è®¢å•çš„æƒ…å†µ
        with open(f"{task_output_dir}/task4_rules.csv", "w", encoding='utf-8') as f:
            f.write("æ— é€€æ¬¾è®¢å•æ•°æ®")
        with open(f"{task_output_dir}/task4_frequent_itemsets.csv", "w", encoding='utf-8') as f:
            f.write("æ— é€€æ¬¾è®¢å•æ•°æ®")
        print("âš ï¸ ä»»åŠ¡4ï¼šæ²¡æœ‰é€€æ¬¾è®¢å•ï¼Œæœªç”Ÿæˆé¢‘ç¹é¡¹é›†ä¸è§„åˆ™")
        return None

# ä¸»å‡½æ•°
def main():
    print("ğŸ“¥ æ­£åœ¨åŠ è½½æ•°æ®...")
    data = load_jsonl_as_list(DATA_PATH)

    print("ğŸš€ æ‰§è¡Œä»»åŠ¡1...")
    task1(data)

    print("ğŸš€ æ‰§è¡Œä»»åŠ¡2...")
    task2(data)

    print("ğŸš€ æ‰§è¡Œä»»åŠ¡3...")
    task3(data)

    print("ğŸš€ æ‰§è¡Œä»»åŠ¡4...")
    task4(data)



    # print("âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼Œç»“æœä¿å­˜åœ¨ results_major ç›®å½•")

if __name__ == "__main__":
    main()
